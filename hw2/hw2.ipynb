{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "LOOKING AT WIDTH = 32, DEPTH = 2 \n",
      "\n"
     ]
    },
    {
     "ename": "IndexError",
     "evalue": "shape mismatch: indexing arrays could not be broadcast together with shapes (400,) (100,) ",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[12], line 69\u001b[0m\n\u001b[1;32m     67\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m width \u001b[38;5;129;01min\u001b[39;00m allPossibleWidths:\n\u001b[1;32m     68\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m depth \u001b[38;5;129;01min\u001b[39;00m allPossibleDepths:\n\u001b[0;32m---> 69\u001b[0m         avg_train_loss, avg_val_loss \u001b[38;5;241m=\u001b[39m \u001b[43mperform_cross_validation\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mwidth\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdepth\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     70\u001b[0m         results\u001b[38;5;241m.\u001b[39mappend({\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mwidth\u001b[39m\u001b[38;5;124m'\u001b[39m: width,\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdepth\u001b[39m\u001b[38;5;124m'\u001b[39m: depth,\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mavg_val_loss\u001b[39m\u001b[38;5;124m'\u001b[39m: avg_val_loss, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mavg_train_loss\u001b[39m\u001b[38;5;124m'\u001b[39m: avg_train_loss})\n\u001b[1;32m     72\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124mFINAL RESULTS:\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "Cell \u001b[0;32mIn[12], line 43\u001b[0m, in \u001b[0;36mperform_cross_validation\u001b[0;34m(x_train, y_train, width, depth)\u001b[0m\n\u001b[1;32m     41\u001b[0m x_train_fold \u001b[38;5;241m=\u001b[39m x_train[train_index]\n\u001b[1;32m     42\u001b[0m y_train_fold \u001b[38;5;241m=\u001b[39m y_train[train_index]\n\u001b[0;32m---> 43\u001b[0m x_val_fold \u001b[38;5;241m=\u001b[39m \u001b[43mx_train\u001b[49m\u001b[43m[\u001b[49m\u001b[43mval_index\u001b[49m\u001b[43m]\u001b[49m\n\u001b[1;32m     44\u001b[0m y_val_fold \u001b[38;5;241m=\u001b[39m y_train[val_index]\n\u001b[1;32m     45\u001b[0m model \u001b[38;5;241m=\u001b[39m create_model(x_train\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m1\u001b[39m], width, depth)\n",
      "\u001b[0;31mIndexError\u001b[0m: shape mismatch: indexing arrays could not be broadcast together with shapes (400,) (100,) "
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import KFold, train_test_split\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Input\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "trainingArr = pd.read_csv('./train-1.csv')\n",
    "testArr = pd.read_csv('./test.csv')\n",
    "\n",
    "# Convert both to numpy arrays with the same format\n",
    "x_test = testArr.drop('arousal', axis=1).values  # Add .values here\n",
    "y_test = testArr['arousal'].values  # Add .values here\n",
    "x_train = trainingArr.drop('arousal', axis=1).values\n",
    "y_train = trainingArr['arousal'].values\n",
    "\n",
    "allPossibleWidths = [32, 1024]\n",
    "allPossibleDepths = [2, 4]\n",
    "\n",
    "def create_model(curShape, width, depth):\n",
    "    model = Sequential()\n",
    "    model.add(Input(shape=(curShape,)))\n",
    "    for i in range(depth):\n",
    "        model.add(Dense(width, activation='relu'))\n",
    "    model.add(Dense(1, activation='linear'))\n",
    "    model.compile(optimizer=Adam(learning_rate=0.5), loss='mse', metrics=['mae'])\n",
    "    return model\n",
    "\n",
    "def perform_cross_validation(x_train, y_train, width, depth):\n",
    "    print(f\"\\nLOOKING AT WIDTH = {width}, DEPTH = {depth} \\n\")\n",
    "    fold_train_losses = []\n",
    "    fold_val_losses = []\n",
    "    kf = KFold(n_splits=5)\n",
    "    \n",
    "    \n",
    "    for (train_index, val_index) in enumerate(kf.split(x_train), 1):\n",
    "        x_train_fold = x_train[train_index]\n",
    "        y_train_fold = y_train[train_index]\n",
    "        x_val_fold = x_train[val_index]\n",
    "        y_val_fold = y_train[val_index]\n",
    "        model = create_model(x_train.shape[1], width, depth)\n",
    "        history = model.fit(\n",
    "            x_train_fold, \n",
    "            y_train_fold, \n",
    "            validation_data=(x_val_fold, y_val_fold),\n",
    "            epochs=50,\n",
    "            verbose=0\n",
    "        )\n",
    "        \n",
    "        # ONLY STORE LAST LOSS\n",
    "        fold_train_losses.append(history.history['loss'][-1])\n",
    "        fold_val_losses.append(history.history['val_loss'][-1])\n",
    "\n",
    "    \n",
    "    # taking mean of loss for validation and training\n",
    "    avg_train_loss = np.mean(fold_train_losses)\n",
    "    avg_val_loss = np.mean(fold_val_losses)\n",
    "    return avg_train_loss, avg_val_loss\n",
    "\n",
    "\n",
    "results = []\n",
    "\n",
    "for width in allPossibleWidths:\n",
    "    for depth in allPossibleDepths:\n",
    "        avg_train_loss, avg_val_loss = perform_cross_validation(x_train, y_train, width, depth)\n",
    "        results.append({'width': width,'depth': depth,'avg_val_loss': avg_val_loss, 'avg_train_loss': avg_train_loss})\n",
    "\n",
    "print(\"\\nFINAL RESULTS:\\n\")\n",
    "for result in results:\n",
    "    print(f\"\\n[Width: {result['width']}, Depth: {result['depth']}]\")\n",
    "    print(f\"Average Train Loss: {result['avg_train_loss']}\")\n",
    "    print(f\"Average Validation Loss: {result['avg_val_loss']}\")\n",
    "\n",
    "# getting best hyperparameters by looking through every hyperparameters object storing its avgTraining and avg validation loss and finding the min.\n",
    "curMinVal = float('inf')\n",
    "curBestObj = None\n",
    "for result in results:\n",
    "    if result[\"avg_val_loss\"] < curMinVal:\n",
    "        curMinVal = result[\"avg_val_loss\"]\n",
    "        curBestObj = result\n",
    "\n",
    "print(\"\\nBEST HYPEPARAMETERS\")\n",
    "print(f\"Width: {curBestObj['width']}\")\n",
    "print(f\"Depth: {curBestObj['depth']}\")\n",
    "print(f\"Average Validation Loss: {curBestObj['avg_val_loss']}\")\n",
    "print(f\"Average Training Loss {curBestObj['avg_train_loss']}\")\n",
    "\n",
    "\n",
    "# since im implementing early stopping, need to keep track of validation loss with 90:10 split\n",
    "x_train_final, x_val_final, y_train_final, y_val_final = train_test_split(\n",
    "    x_train, y_train, test_size=0.1, random_state=42\n",
    ")\n",
    "\n",
    "\n",
    "# doing final training with best hyperparameters\n",
    "model2 = create_model(x_train.shape[1], curBestObj['width'], curBestObj['depth'])\n",
    "early_stop2 = EarlyStopping(\n",
    "    monitor='val_loss',\n",
    "    patience=10,\n",
    "    restore_best_weights=True,\n",
    "    verbose=0\n",
    ")\n",
    "\n",
    "history2 = model2.fit(\n",
    "    x_train_final, \n",
    "    y_train_final,\n",
    "    validation_data=(x_val_final, y_val_final),\n",
    "    epochs=100, \n",
    "    callbacks=[early_stop2],\n",
    "    verbose=0\n",
    ")\n",
    "\n",
    "test_loss, test_mae = model2.evaluate(x_test, y_test, verbose=0)\n",
    "print(f\"\\n Final Test Loss: {test_loss}\")\n",
    "\n",
    "#plot everything\n",
    "plt.figure(figsize=(12, 6))\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.yscale(\"log\")\n",
    "plt.plot(history2.history['loss'], label='Training Loss')\n",
    "plt.plot(history2.history['val_loss'], label='Validation Loss')\n",
    "plt.axhline(y=test_loss, color='r', label='Test Loss')\n",
    "plt.title('Model Loss')\n",
    "plt.ylabel('Loss ')\n",
    "plt.xlabel('Epoch')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
